#!/usr/bin/env python
from __future__ import print_function
import sys
import imp
import os
import pickle
import optparse
import time
import shutil
import datetime
import multiprocessing as mp
from shutil import copyfile,rmtree


try:
    from Payette_config import *
except ImportError:
    print("ERROR: Toolset/Payette_config.py must be autogenerated "
          "by buildPayette.py before using Payette")
    sys.exit(100)
    pass

from Source.Payette_utils import *
import Source.Payette_container as pcntnr
import Source.Payette_driver as pdrvr

def runPayette(argc,argv):

    global opts,restart,user_input_dict

    # *************************************************************************
    # -- command line option parsing
    usage = "usage: runPayette [options] <input file>"
    parser = optparse.OptionParser(usage = usage, version = "%prog 1.0")
    parser.add_option("--clean",
                      dest = "clean",
                      action = "store_true",
                      default = False,
                      help = ("Clean Payette auxilary output and exit "
                      "[default: %default]"))
    parser.add_option("--cleanall",
                      dest = "cleanall",
                      action = "store_true",
                      default = False,
                      help = "Clean ALL Payette output and exit [default: %default]")
    parser.add_option("--cchar",
                      dest = "cchar",
                      action = "store",
                      default = None,
                      help = ("Additional comment characters for input file "
                              "[default: %default]"))
    parser.add_option("-d","--debug",
                      dest = "debug",
                      action = "store_true",
                      default = False,
                      help = "Global debug flag [default: %default]")
    parser.add_option("--input-str",
                      dest = "inputstr",
                      action = "store",
                      default = None,
                      help = ("Input string for simulation instead of file "
                              "[default: %default]"))
    parser.add_option("-j","--nproc",
                      dest = "nproc",
                      type = int,
                      default = 1,
                      action = "store",
                      help="Number of simultaneous jobs [default: %default]")
    parser.add_option("-k","--keep",
                      dest = "keep",
                      action = "store_true",
                      default = False,
                      help = ("Do not overwrite old output files with each run "
                              "[default: %default]"))
    parser.add_option("-m","--materials",
                      dest = "mtls",
                      default = False,
                      action = "store_true")
    parser.add_option("--no-restart",
                      dest = "norestart",
                      action = "store_true",
                      default = False,
                      help = "Do not save restart files [default: %default]")
    parser.add_option("--no-writeprops",
                      dest = "nowriteprops",
                      action = "store_true",
                      default = False,
                      help = "Do not write checked parameters [default: %default]")
    parser.add_option("-p","--princ",
                      dest = "principal",
                      action = "store_true",
                      default = False,
                      help = ("Diagonalize input arguments and run problem in "
                              "principal coordinates [default: %default]"))
    parser.add_option("--proportional",
                      dest = "proportional",
                      action = "store_true",
                      default = False,
                      help = ("Use proportional loading for prescribed stress"
                              "components. [default: %default]"))
    parser.add_option("-s","--strict",
                      dest = "strict",
                      action = "store_true",
                      default = False,
                      help = ("Do not use approximations to update kinematic "
                              "quantities (slow) [default: %default]"))
    parser.add_option("-S","--sqa",
                      dest = "sqa",
                      action = "store_true",
                      default = False,
                      help = ("Run additional verification/sqa checks "
                              "[default: %default]"))
    parser.add_option("-t",
                      dest = "timing",
                      action = "store_true",
                      default = False,
                      help = ("time execution of Payette runs [default: %default]"))
    parser.add_option("-T","--use-table",
                      dest = "use_table",
                      action = "store_true",
                      default = False,
                      help = ("Update kinematic quantities from input when "
                              "applicable [default: %default]"))
    parser.add_option("--test-restart",
                      dest = "testrestart",
                      action = "store_true",
                      default = False,
                      help = "Test restart capabilities [default: %default]")
    parser.add_option("-v","--verbosity",
                      dest = "verbosity",
                      type = "choice",
                      choices = ["0","1","2","3","4"],
                      default = "3",
                      action = "store",
                      help = "Verbosity default: %default]")
    parser.add_option("-w","--write-vandd",
                      dest = "write_vandd_table",
                      action = "store_true",
                      default = False,
                      help = ("Write equivalent velocity and displacement table "
                              "[default: %default]"))
    (opts,args) = parser.parse_args(argv)

    # @tjf: restart is temporarily disabled

    opts.norestart = True
    payette_exts = [".log",".math1",".math2",".props",".echo",".prf"]
    if opts.cleanall:
        payette_exts.extend([".out"])
        opts.clean = True

    if opts.clean:
        cleaned = False
        # clean all the payette output and exit
        for arg in args:
            argdir,argbas = os.path.split(os.path.realpath(arg))
            argnam,argext = os.path.splitext(arg)
            if argnam not in [os.path.splitext(x)[0] for x in os.listdir(argdir)]:
                print("WARNING: no Payette output for {0} found in {1}"
                      .format(arg,argdir))
                continue
            print("INFO: cleaning output for {0}".format(argnam))
            for ext in payette_exts:
                try:
                    os.remove( argnam + ext)
                    cleaned = True
                except: pass
                continue
            continue
        msg = "INFO: output cleaned" if cleaned else "WARNING: no ouput cleaned"
        sys.exit(msg)

    # ------------------------------------------------- start: get the user input
    restart = False
    input_lines = []
    if opts.inputstr:
        # user gave input directly
        input_lines.extend(opts.inputstr.split("\n"))
        pass

    # make sure input file is given and exists
    if len(args) < 1 and not input_lines:
        parser.print_help()
        parser.error("No input given")
        pass

    # check restart files
    rfiles = [x for x in args if os.path.splitext(x)[1] == ".prf"]
    if len(rfiles) > 1:
        parser.error(str(len(rfiles)) + " restart files given, but only one "
                     "restart file can be processed at a time")

    elif len(rfiles) and len(rfiles) != len(args):
        # choose to run a single restart file or input files, but don't mix
        parser.error("Cannot process both restart and input files at same time")

    elif len(rfiles):
        # check to see if the input file exists and get it info
        rfile = rfiles[0]
        if not os.path.isfile(rfile):
            parser.error("Restart file {0} not found".format(rfile))
            pass
        restart = True
        with open(rfile,"rb") as f: the_model = pickle.load(f)
        user_input_dict = {"restart":the_model}

    else:
        # get a list of all input files, order of where to look for file f:
        # 1: f
        # 2: realpath(f)
        # 3: join(Aux/Inputs,f)
        # 4: splitext(f)[0] + .inp
        # 5: join(Aux/Inputs,splitext(f)[0] + .inp)
        foundf, badf = [], []
        for iarg,arg in enumerate(args):
            f = None
            fbase,fext = os.path.splitext(arg)
            if not arg: continue
            if fext == ".prf":
                # one last check for restart files
                parser.error("Cannot process both restart and input "
                             "files at same time")
            elif os.path.isfile(arg):
                f = arg
            elif os.path.isfile(os.path.realpath(arg)):
                f = os.path.realpath(arg)
            elif os.path.isfile(os.path.join(Payette_Inputs,arg)):
                f = os.path.join(Payette_Inputs,arg)
                writeMessage(__file__,"Using " + f + " as input")
            elif not fext or fext == ".":
                # add .inp extension to arg
                arginp = fbase + ".inp"
                if os.path.isfile(arginp):
                    f = arginp
                    writeMessage(__file__,"Using " + f + " as input")
                elif os.path.isfile(os.path.join(Payette_Inputs,arginp)):
                    f = os.path.join(Payette_Inputs,arginp)
                    writeMessage(__file__,"Using " + f + " as input")
                else: pass
                pass

            if not f:
                writeWarning(__file__,"{0} not found in {1}, {2}, or {3}"
                             .format(arg,os.path.dirname(os.path.realpath(arg)),
                                     os.getcwd(),Payette_Inputs))
                badf.append(arg)
                continue

            if f in foundf:
                parser.error("{0} given multiple times".format(arg))
                pass

            foundf.append(f)
            continue

        if badf:
            writeWarning(__file__,"The following files were not found: {0}"
                         .format(", ".join(badf)))
            pass

        if not foundf and not input_lines:
            parser.print_help()
            parser.error("No input files found")
            pass

        # we now have a list of input files, put there contents in to input lines
        for f in foundf:
            input_lines.extend(open(f,"r").readlines())
            continue

        # read the user input
        user_input_dict = readUserInput(input_lines,opts.cchar)
        if not user_input_dict:
            sys.exit("ERROR: user input not found in {0:s}".format(infile))
            pass
        pass
    # ------------------------------------------------------- end: get user input

    # number of processors
    nproc = min(min(mp.cpu_count(),opts.nproc),len(user_input_dict))
    opts.verbosity = int(opts.verbosity) if nproc == 1 else 0

    if nproc > 1:
        writeWarning(__file__,
                     "Running with multiple processors.  Logging to the console\n"
                     "         has been turned off.  If a job hangs, [ctrl-c] at the\n"
                     "         console will not shut down Payette.  Instead, put the job\n"
                     "         in the background with [ctrl-z] and then kill it")

    # loop through simulations and run them
    if opts.timing: t0 = time.time()
    if nproc > 1 and len(user_input_dict.keys()) > 1:
        p = mp.Pool(processes=nproc)
        p.map(runJob,user_input_dict.keys())
        p.close()
        p.join()
    else:
        for key in user_input_dict:
            runJob(key)
            continue
        pass
    if opts.timing: printFinalTimingInfo(t0)

    return 0

def runJob(key):
    # instantiate Payette object
    if opts.timing: t0 = time.time()

    if restart:
        # @tjf: restart is temporarily disabled
        sys.exit("restart is disabled until fixed")
        the_model = user_input_dict[key]
        the_model.setupRestart()
    else: the_model = pcntnr.Payette(key,user_input_dict[key],opts)

    # run the problem
    if opts.timing: t1 = time.time()
    solve = pdrvr.runProblem(the_model,restart=restart)
    if opts.timing: t2 = time.time()
    if solve == 0:
        reportMessage(__file__,"%s Payette simulation ran to completion"
                      %the_model.name)
    else:
        reportMessage(__file__,"%s Payette simulation failed\n\n"
                      %the_model.name)
        return 1

    # finish up
    the_model.finish()
    del the_model

    # print timing info
    if opts.timing: printTimingInfo(t0,t1,t2,the_model.name)
    return

def printTimingInfo(t0,t1,t2,name=None):
    ttot = time.time() - t0
    texe = t2 - t1
    print("\n-------------- %s timing info --------------"%name)
    print("total problem execution time:\t%f"%texe)
    print("total simulation time:\t\t%f\n"%ttot)
    return None

def printFinalTimingInfo(t0):
    ttot = time.time() - t0
    print("\n-------------- simulation timing info --------------")
    print("total simulation time:\t\t%f"%ttot)
    return None

def testPayette(argc,argv):
    """
    NAME
       testPayette

    PURPOSE
       walk through and run the Payette test simulations, compare results
       against the accepted results

    AUTHORS
       Tim Fuller, Sandia National Laboratories, tjfulle@sandia.gov
       M. Scot Swan, Sandia National Laboratories, mswan@sandia.gov
    """
    import platform
    import datetime # For the date of when the tests were run
    import getpass  # For finding the username of the person running this
    from Source.Payette_test import findTests
    import Source.Payette_notify

    global testresdir,rantests,topts,term_width,info_width

    # These are used to control formatting for testPayette
    term_width = 80
    info_width = 25

    # *************************************************************************
    # -- command line option parsing
    usage = "usage: testPayette [options]"
    parser = optparse.OptionParser(usage = usage, version = "%prog 1.0")
    parser.add_option("-k",
                      dest = "KEYWORDS",
                      action = "append",
                      default = [],
                      help = "keywords: [%default]")
    parser.add_option("-K",
                      dest = "NOKEYWORDS",
                      action = "append",
                      default = [],
                      help = "keyword negation: [%default]")
    parser.add_option("-t",
                      dest = "SPECTESTS",
                      action = "append",
                      default = [],
                      help = ("specific tests to run, more than 1 collected: "
                              "[%default]"))
    parser.add_option("-d","--dir",
                      dest="TESTDIR",
                      action="store",
                      default=Payette_Tests,
                      help="Directory to scan for benchmarks [default: %default].")
    parser.add_option("-i","--index",
                      dest="INDEX",
                      action="store_true",
                      default=False,
                      help="Print benchmarks index [default: %default].")
    parser.add_option("-r","--run",
                      dest="RUN",
                      action="store_true",
                      default=False,
                      help="Run benchmarks. [default: %default].")
    parser.add_option("-F",
                      dest="FORCERERUN",
                      action="store_true",
                      default=False,
                      help=("Force benchmarks to be run again if already ran. "
                            "[default: %default]."))
    parser.add_option("-j","--nproc",
                      dest = "nproc",
                      type = int,
                      default = 1,
                      action = "store")
    parser.add_option("-b","--buildpayette",
                      dest="buildpayette",
                      action="store_true",
                      default=False,
                      help=("build payette [default: %default]."))
    parser.add_option("-p","--postprocess",
                      dest = "POSTPROCESS",
                      action = "store_true",
                      default=False,
                      help=("Generate all plots for all tests to be viewed in "
                            "browser"))
    parser.add_option("--notify",
                      dest = "NOTIFY",
                      action = "store_true",
                      default=False,
                      help=("Sends an email with the test results to the "
                            "mailing list."))
    parser.add_option("-I",
                      dest = "IGNOREERROR",
                      action = "store_true",
                      default = False,
                      help=("Ignore noncomforming tests [default: %default]"))
    parser.add_option("-e","--electro",
                      dest = "ELECTROMECH",
                      action = "store_true",
                      default = False,
                      help=("Run electromechanics tests [default: %default]"))

    iam = "testPayette"

    (topts,args) = parser.parse_args(argv)

    # number of processors
    nproc = min(mp.cpu_count(),topts.nproc)

    # assume the user wants to run the tests
    if not topts.RUN and not topts.INDEX: topts.RUN = True

    # adjust keywords
    if not topts.ELECTROMECH:
        topts.NOKEYWORDS.append("electromech")

    # find tests
    inform(iam,"Gathering Payette tests from {0}".format(topts.TESTDIR))
    errors, found_tests = findTests(topts.KEYWORDS,topts.NOKEYWORDS,
                                    topts.SPECTESTS,topts.TESTDIR)

    # sort conforming tests from long to fast
    fast_tests = [ val for key,val in found_tests["fast"].items() ]
    medium_tests = [ val for key,val in found_tests["medium"].items() ]
    long_tests = [ val for key,val in found_tests["long"].items() ]
    conforming = long_tests + medium_tests + fast_tests

    # find mathematica notebooks
    mathnbs = {}
    for (dirname,dirs,names) in os.walk(topts.TESTDIR):
        root, base = os.path.split(dirname)
        if base == "nb":
            # a notebook directory has been found, see if there are any
            # conforming tests that use it
            if [x for x in conforming if root in x]:
                mathnbs[root.split(topts.TESTDIR+os.sep)[1]] = [
                    os.path.join(dirname,x) for x in names
                    if x.endswith(".nb") or x.endswith(".m") ]
                pass
            pass
        continue

    if errors and not topts.IGNOREERROR:
        sys.exit("fix nonconforming benchmarks before continuing")
        pass

    inform(iam,"Found {0} Payette tests".format(len(conforming)),end="\n\n")

    if topts.INDEX:
        out = sys.stderr
        out.write("\n\nBENCHMARK INDEX\n\n")
        for speed, tests in found_tests.items():
            for py_mod, py_file in tests.items():
                # load module
                py_path = [os.path.dirname(py_file)]
                fp, pathname, description = imp.find_module(py_mod,py_path)
                py_module = imp.load_module(py_mod,fp,pathname,description)
                fp.close()
                test = py_module.Test()
                out.write(term_width*"="+"\n")
                out.write("Name:  {0}\n".format(test.name))
                out.write("Owner: {0}\n\n".format(test.owner))
                out.write("Description:\n{0}".format(test.description))

                out.write("\nKeywords:\n")
                for kw in test.keywords: out.write("    {0}\n".format(kw))
                continue
            continue
        pass

    if topts.RUN:
        # start the timer
        runtimer = time.time()

        # Make a TestResults directory named "TestResults.{platform}"
        testresdir = os.path.join(os.getcwd(),"TestResults.%s"%platform.system())
        if topts.buildpayette:
            if os.path.isdir(testresdir):
                testresdir0 = "%s_0"%testresdir
                shutil.move(testresdir,testresdir0)
            else: testresdir0 = None
            pass

        if not os.path.isdir(testresdir): os.mkdir(testresdir)

        old_results = {}
        summpy = os.path.join(testresdir,"summary.py")
        summhtml = os.path.splitext(summpy)[0] + ".html"
        if os.path.isfile(summpy):
            try:
                py_path = [os.path.dirname(summpy)]
                py_mod = get_module_name(summpy)
                fp, pathname, description = imp.find_module(py_mod,py_path)
                py_module = imp.load_module(py_mod,fp,pathname,description)
                fp.close()
                try: old_results = py_module.payette_test_results
                except: copyfile(summpy,os.path.join(testresdir,"summary_orig.py"))
                try: os.remove("{0}c".format(summpy))
                except: pass
                pass
            except: pass
            pass

        # check type of old_results, if not dict start over with empty dict
        if not isinstance(old_results,dict):
            old_results = {}

        # Put all run tests in a flattened list for checking if test has been run
        if old_results:
            rantests = [ x for y in old_results.values() for x in y ]
        else:
            rantests = []
            pass

        # reset the test results
        test_statuses = ["pass","diff","fail","notrun","bad input","failed to run"]
        test_res = {}
        for i in test_statuses:
            test_res[i] = {}
            continue


        print("="*term_width)
        print("Running {0} benchmarks:".format(len(conforming)))
        print("="*term_width)

        # run the tests on multiple processors using the multiprocessor map ONLY
        # if nprocs > 1. For debug purposes, when nprocs=1, run without using the
        # multiprocessor map because it makes debugging worse than it should be.
        if nproc == 1:
            all_results = [ runPayetteTest(test) for test in conforming ]

        else:
            p = mp.Pool(processes=nproc)
            all_results = p.map(runPayetteTest,conforming)
            p.close()
            p.join()

        ttot = time.time()-runtimer
        print("="*term_width)

        # copy the mathematica notebooks to the output directory
        for mtldir, mathnb in mathnbs.items():
            for item in mathnb:
                fbase = os.path.basename(item)
                fold = os.path.join(testresdir,mtldir,fbase)

                try: os.remove(fold)
                except: pass

                if item.endswith(".m"):
                    # don't copy the .m file, but write it, replacing rundir
                    # and demodir with testresdir
                    with open(fold,"w") as f:
                        for line in open(item,"r").readlines():
                            demodir = os.path.join(testresdir,mtldir) + os.sep
                            rundir = os.path.join(testresdir,mtldir) + os.sep
                            if r"$DEMODIR" in line:
                                line = 'demodir="{0:s}"\n'.format(demodir)
                            elif r"$RUNDIR" in line:
                                line = 'rundir="{0:s}"\n'.format(rundir)
                            else:
                                pass
                            f.write(line)
                            continue
                        pass
                    continue

                else:
                    # copy the notebook files
                    shutil.copyfile(item,fold)
                    pass

                continue

            continue

        # all_results is a large list of the summary of every test. Go through it
        # an use the information to construct the test_res dictionary of the
        # form:
        #    test_res["notrun"] = ...
        #    test_res["pass"] = ...
        #    test_res["diff"] = ...
        #    test_res["failed"] = ...
        for item in all_results:
            for name, summary in item.items():
                status = summary["status"] #@tjf???
                if status not in test_statuses:
                    msg = ("return code {0} from {1} not recognized"
                           .format(status,name))
                    warn(iam,msg)
                    continue
                tcompletion = summary["completion time"]
                benchdir = summary["benchmark directory"]
                keywords = summary["keywords"]
                test_res[status][name] = {"benchmark directory":benchdir,
                                          "completion time":tcompletion,
                                          "keywords":keywords}
                continue
            continue

        nnotrun = len(test_res["notrun"])
        nfail = len(test_res["fail"])
        npass = len(test_res["pass"])
        ndiff = len(test_res["diff"])
        nfailtorun = len(test_res["failed to run"])
        txtsummary = ( "SUMMARY\n" +
                 "{0} benchmarks took {1:.2f}s.\n".format(len(conforming),ttot) +
                 "{0} benchmarks passed\n".format(npass) +
                 "{0} benchmarks diffed\n".format(ndiff) +
                 "{0} benchmarks failed\n".format(nfail) +
                 "{0} benchmarks failed to run\n".format(nfailtorun) +
                 "{0} benchmarks not run\n".format(nnotrun) +
                 "For a summary of which benchmarks passed, diffed, failed, " +
                 "or not run, see\n{0}".format(summhtml))

        ######################################################################
        # Make a long summary including the names of what passed and what didn't
        # as well as system information.
        str_date = datetime.datetime.today().strftime("%A, %d. %B %Y %I:%M%p")
        try:
            py_version = "{0}.{1}.{2}".format(sys.version_info.major,
                                              sys.version_info.minor,
                                              sys.version_info.micro)
        except:
            py_version = str(sys.version_info)
            pass

        longtxtsummary = (
             "="*term_width+"\nLONG SUMMARY\n"+
             "{0} benchmarks took {1:.2f}s.\n".format(len(conforming),ttot) +
             "{0:^{1}}\n".format("{0:-^30}".format(" system information "),term_width)+
             "   Date complete:    {0:<}\n".format(str_date)+
             "   Username:         {0:<}\n".format(getpass.getuser())+
             "   Hostname:         {0:<}\n".format(os.uname()[1])+
             "   Platform:         {0:<}\n".format(sys.platform)+
             "   Python Version:   {0:<}\n".format(py_version))

        # List each category (diff, fail, notrun, and pass) and the tests
        test_result_statuses = test_res.keys()
        test_result_statuses.sort()
        for stat in test_result_statuses:
            names = test_res[stat].keys()
            header = "{0:-^30}".format(" "+stat+" ({0}) ".format(len(names)))
            longtxtsummary += "{0:^{1}}\n".format(header,term_width)
            if len(names) == 0:
#                longtxtsummary += "None\n"
                continue
            elif stat == "notrun":
#                longtxtsummary += "None\n"
                continue
            for name in names:
                try:
                    t = "{0:.2f}s.".format(test_res[stat][name]["completion time"])
                except:
                    t = str(test_res[stat][name]["completion time"])
                    pass
                longtxtsummary += "  {0:>8}   {1}\n".format(t,name)
                continue
            continue
        longtxtsummary += "="*term_width + "\n"
        # longtxtsummary is finished at this point
        ######################################################################

        # This sends an email to everyone on the mailing list.
        if topts.NOTIFY:
            print("Sending results to mailing list.")
            Payette_notify.notify("Payette Benchmarks",longtxtsummary)
            pass

        print(longtxtsummary)
        print("="*term_width)
        print(txtsummary)
        print("="*term_width)

        # write out the results to the summary file
        writePyTestSummary(summpy,test_res)
        writeHTMLTestSummary(summhtml,test_res)

        # cleanup our tracks
        for (dirname,dirs,names) in os.walk(topts.TESTDIR):
            for name in names:
                fbase,fext = os.path.splitext(name)
                delext = [".so",".pyo",".pyc",".log",".out",".prf"]
                if fext in delext: os.remove(os.path.join(dirname,name))
                continue
            continue

        if topts.buildpayette:
            shutil.rmtree(testresdir)
            if testresdir0: shutil.move(testresdir0,testresdir)
            pass
        pass

    return 0

def runPayetteTest(py_file):
    cwd = os.getcwd()
    py_path = [os.path.dirname(py_file)]
    py_mod = get_module_name(py_file)
    fp, pathname, description = imp.find_module(py_mod,py_path)
    py_module = imp.load_module(py_mod,fp,pathname,description)
    fp.close()

    test = py_module.Test()

    # directory where test will be run
    testbase = os.path.dirname(py_file).split(Payette_Tests + os.sep)[1]
    benchdir = os.path.join(testresdir,testbase,test.name)

    # check if benchmark has been run
    ran = [ x for x in rantests if x == test.name ]

    if not topts.FORCERERUN and ran and os.path.isdir(benchdir):
        print(  "%s"%(test.name)
                + " "*(50-len(test.name))
                + "{0:>10s}".format("notrun\n")
                + "Test already ran. "
                + "Use -F option to force a rerun")
        result = { test.name:{"status":"notrun",
                              "keywords":test.keywords,
                              "completion time":"NA",
                              "benchmark directory":benchdir } }
        return result

    # Let the user know which test is running
    print(  "{0:<{1}}".format(test.name,term_width-info_width)
            + "{0:>{1}s}".format("RUNNING",info_width))

    # Create benchmark directory and copy the input and baseline files into the
    # new directory
    if os.path.isdir(benchdir):
        rmtree(benchdir)
    os.makedirs(benchdir)

    # copy input file, if any
    if test.infile:
        copyfile(test.infile,
                 os.path.join(benchdir,os.path.basename(test.infile)))
        pass

    # copy the python test file and make it executable
    copyfile(py_file,
             os.path.join(benchdir,os.path.basename(py_file)))
    os.chmod(os.path.join(benchdir,os.path.basename(py_file)),0o750)

    # link the config file
    test_config_file = os.path.join(benchdir,os.path.basename(Payette_config_file))
    os.symlink(Payette_config_file,test_config_file)

    if test.baseline:
        if isinstance(test.baseline,list):
            for base_f in test.baseline:
                os.symlink(base_f,os.path.join(benchdir,os.path.basename(base_f)))
                continue
        else:
            os.symlink(test.baseline,
                       os.path.join(benchdir,os.path.basename(test.baseline)))
            pass
        pass

    # move to the new directory and run the test
    os.chdir(benchdir)
    starttime = time.time()

    retcode = test.runTest()

    if topts.POSTPROCESS and os.path.isfile(test.outfile):
        import postprocess as PP
        PP.postprocess(test.outfile,verbosity=0)
        pass

    retcode = ("bad input" if retcode == test.badincode else
               "pass" if retcode ==  test.passcode else
               "diff" if retcode ==  test.diffcode else
               "fail" if retcode ==  test.failcode else
               "failed to run" if retcode == test.failtoruncode else
               "unkown")

    # Print output at completion
    tcompletion = time.time()-starttime
    info_string = "{0} ({1:6.02f}s)".format(retcode.upper(),tcompletion)
    print(  "{0:<{1}}".format(test.name,term_width-info_width)
            + "{0:>{1}s}".format(info_string,info_width))

    # return to the directory we came from
    os.chdir(cwd)
    result = { test.name:{"status":retcode,
                          "keywords":test.keywords,
                          "completion time":tcompletion,
                          "benchmark directory":benchdir } }
    return result



def writePyTestSummary(fname,results):
    """ write summary of the results dictionary to python file """
    # the results dictionary is of the form
    # results = { {status: {name: { "benchmark directory":benchdir,
    #                               "completion time":tcompletion,
    #                               "keywords":keywords } } } }
    with open(fname,"w") as f:
        f.write("payette_test_results = {}\n")
        for stat in results:
            # key is one of diff, pass, fail, notrun
            # names are the names of the tests
            f.write("payette_test_results['{0}']=[".format(stat))
            f.write(",".join(["'{0}'".format(x) for x in results[stat].keys()]))
            f.write("]\n")
            continue
        pass
    return

def writeHTMLTestSummary(fname,results):
    """ write summary of the results dictionary to html file """
    # the results dictionary is of the form
    # results = { {status: {name: { "benchmark directory":benchdir,
    #                               "completion time":tcompletion,
    #                               "keywords":keywords } } } }
    resd = os.path.dirname(fname)
    resdb = os.path.basename(resd)
    npass,nfail,ndiff,nskip = [len(results[x]) for x in
                               ["pass","fail","diff","notrun"]]
    with open(fname,"w") as f:
        # write header
        f.write("<html>\n<head>\n<title>Test Results</title>\n</head>\n")
        f.write("<body>\n<h1>Summary</h1>\n")
        f.write("<ul>\n")
        f.write("<li> Directory: %s </li>\n"%resd)
        f.write("<li> Options: %s </li>\n"%(" ".join(sys.argv[1:])))
        f.write("<li> %i pass, %i diff, %i fail, %i notrun </li>\n"
                %(npass,ndiff,nfail,nskip))
        f.write("</ul>\n")

        # write out details test that fail, diff, pass, notrun
        for stat in results.keys():
            f.write("<h1>Tests that showed '%s'</h1>\n<ul>\n"%stat)
            for test in results[stat]:
                tresd = results[stat][test]["benchmark directory"]
                tresdb = results[stat][test]["benchmark directory"]
                f.write("<li>%s  %s</li>\n"%(test,tresdb))
                f.write("<ul>\n")
                f.write("<li>Files: \n")
                files = os.listdir(tresd)
                for ff in files:
                    fpath = os.path.join(tresd,ff)
                    f.write("<a href='%s' type='text/plain'>%s</a> \n"%(fpath,ff))
                    continue
                keywords = "  ".join(results[stat][test]["keywords"])
                try:
                    tcompletion = ("{0:.2f}s."
                                   .format(results[stat][test]["completion time"]))
                except:
                    tcompletion = str(results[stat][test]["completion time"])
                    pass
                status = "Exit {0} {1}".format(stat,tcompletion)
                for myfile in files:
                    if myfile.endswith(".out.html") and topts.POSTPROCESS:
                        tf = os.path.join(tresd,myfile)
                        f.write("<li><a href='{0}'>PostProcessing</a>\n".format(tf))
                f.write("<li>Keywords: %s\n"%(keywords))
                f.write("<li>Status: %s\n"%(status))
                f.write("</ul>\n")
                continue
            f.write("</ul>\n")
            continue
        pass
    return

def Payette(args):
    """
    NAME
       Payette

    PURPOSE
       Main function that calls either runPayette or testPayette

    AUTHORS
       Tim Fuller, Sandia National Laboratories, tjfulle@sandia.gov
    """
    if "--profile" in args:
        profile = True
        args.remove("--profile")
        import cProfile
    else: profile = False

    if args and args[1] == "test":
        args.remove("test")
        if profile:
            cmd = "testPayette(len(args[1:]),args[1:])"
            f = "payette.prof"
            cProfile.runctx(cmd,globals(),locals(),f)
            payette = 0
        else: payette = testPayette(len(args[1:]),args[1:])

    elif args and args[1] == "run":
        args.remove("run")
        if profile:
            cmd = "runPayette(len(args[1:]),args[1:])"
            f = "payette.prof"
            cProfile.runctx(cmd,globals(),locals(),f)
            payette = 0
        else: payette = runPayette(len(args[1:]),args[1:])

    else:
        print("ERROR: first argument to Payette must be either run or test")
        print_help()
        return 1
        pass

    return payette

def warn(iam,message):
    print("WARNING: {0} [reported by {1}]".format(message,iam))
    return

def inform(iam,message,end="\n"):
#    print("INFO: {0} [reported by {1}]".format(message,iam))
    print("INFO: {0}".format(message),end=end)
    return

def get_module_name(py_file):
    return os.path.splitext(os.path.basename(py_file))[0]

def print_help():
    print("""
NAME
   Payette

PURPOSE
   Payette is a object oriented single element material model driver written in
   python.

USAGE
   Payette <test,run> [options] <filename>
""")
    return

if __name__ == "__main__":

    # Make sure we run this script under python 2.6
    checkPythonVersion()
    payette = Payette(sys.argv)
    sys.exit(payette)


