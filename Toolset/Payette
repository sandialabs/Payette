#!/usr/bin/env python
from __future__ import print_function
import sys
import imp
import os
import pickle
import optparse
import time
import shutil
import datetime
import multiprocessing as mp
from shutil import copyfile,rmtree


try:
    from Payette_config import *
except ImportError:
    print("ERROR: Toolset/Payette_config.py must be autogenerated "
          "by buildPayette.py before using Payette")
    sys.exit(100)

from Source.Payette_utils import *

import Source.Payette_container as pcntnr
import Source.Payette_driver as pdrvr

def runPayette(argc,argv):

    global opts,restart,user_input_dict

    # *************************************************************************
    # -- command line option parsing
    usage = "usage: runPayette [options] <input file>"
    parser = optparse.OptionParser(usage = usage, version = "%prog 1.0")
    parser.add_option("--clean",
                      dest = "clean",
                      action = "store_true",
                      default = False,
                      help = ("Clean Payette auxilary output and exit "
                      "[default: %default]"))
    parser.add_option("--cleanall",
                      dest = "cleanall",
                      action = "store_true",
                      default = False,
                      help = "Clean ALL Payette output and exit [default: %default]")
    parser.add_option("--cchar",
                      dest = "cchar",
                      action = "store",
                      default = None,
                      help = ("Additional comment characters for input file "
                              "[default: %default]"))
    parser.add_option("-d","--debug",
                      dest = "debug",
                      action = "store_true",
                      default = False,
                      help = "Global debug flag [default: %default]")
    parser.add_option("--input-str",
                      dest = "inputstr",
                      action = "store",
                      default = None,
                      help = ("Input string for simulation instead of file "
                              "[default: %default]"))
    parser.add_option("-j","--nproc",
                      dest = "nproc",
                      type = int,
                      default = 1,
                      action = "store",
                      help="Number of simultaneous jobs [default: %default]")
    parser.add_option("-k","--keep",
                      dest = "keep",
                      action = "store_true",
                      default = False,
                      help = ("Do not overwrite old output files with each run "
                              "[default: %default]"))
    parser.add_option("-m","--materials",
                      dest = "mtls",
                      default = False,
                      action = "store_true")
    parser.add_option("--no-restart",
                      dest = "norestart",
                      action = "store_true",
                      default = False,
                      help = "Do not save restart files [default: %default]")
    parser.add_option("--no-writeprops",
                      dest = "nowriteprops",
                      action = "store_true",
                      default = False,
                      help = "Do not write checked parameters [default: %default]")
    parser.add_option("-p","--princ",
                      dest = "principal",
                      action = "store_true",
                      default = False,
                      help = ("Diagonalize input arguments and run problem in "
                              "principal coordinates [default: %default]"))
    parser.add_option("--proportional",
                      dest = "proportional",
                      action = "store_true",
                      default = False,
                      help = ("Use proportional loading for prescribed stress"
                              "components. [default: %default]"))
    parser.add_option("-s","--strict",
                      dest = "strict",
                      action = "store_true",
                      default = False,
                      help = ("Do not use approximations to update kinematic "
                              "quantities (slow) [default: %default]"))
    parser.add_option("-S","--sqa",
                      dest = "sqa",
                      action = "store_true",
                      default = False,
                      help = ("Run additional verification/sqa checks "
                              "[default: %default]"))
    parser.add_option("-t",
                      dest = "timing",
                      action = "store_true",
                      default = False,
                      help = ("time execution of Payette runs [default: %default]"))
    parser.add_option("-T","--use-table",
                      dest = "use_table",
                      action = "store_true",
                      default = False,
                      help = ("Update kinematic quantities from input when "
                              "applicable [default: %default]"))
    parser.add_option("--test-restart",
                      dest = "testrestart",
                      action = "store_true",
                      default = False,
                      help = "Test restart capabilities [default: %default]")
    parser.add_option("-v","--verbosity",
                      dest = "verbosity",
                      type = "choice",
                      choices = ["0","1","2","3","4"],
                      default = "3",
                      action = "store",
                      help = "Verbosity default: %default]")
    parser.add_option("-w","--write-vandd",
                      dest = "write_vandd_table",
                      action = "store_true",
                      default = False,
                      help = ("Write equivalent velocity and displacement table "
                              "[default: %default]"))
    (opts,args) = parser.parse_args(argv)

    payette_exts = [".log",".math1",".math2",".props",".echo",".prf"]
    if opts.cleanall:
        payette_exts.extend([".out"])
        opts.clean = True

    if opts.clean:
        cleaned = False
        # clean all the payette output and exit
        for arg in args:
            argdir,argbas = os.path.split(os.path.realpath(arg))
            argnam,argext = os.path.splitext(arg)
            if argnam not in [os.path.splitext(x)[0] for x in os.listdir(argdir)]:
                print("WARNING: no Payette output for {0} found in {1}"
                      .format(arg,argdir))
                continue
            print("INFO: cleaning output for {0}".format(argnam))
            for ext in payette_exts:
                try:
                    os.remove( argnam + ext)
                    cleaned = True
                except: pass
                continue
            continue
        msg = "INFO: output cleaned" if cleaned else "WARNING: no ouput cleaned"
        sys.exit(msg)

    # ------------------------------------------------- start: get the user input
    restart = False
    input_lines = []
    if opts.inputstr:
        # user gave input directly
        input_lines.extend(opts.inputstr.split("\n"))
        pass

    # make sure input file is given and exists
    if len(args) < 1 and not input_lines:
        parser.print_help()
        parser.error("No input given")
        pass

    # check restart files
    rfiles = [x for x in args if os.path.splitext(x)[1] == ".prf"]
    if len(rfiles) > 1:
        parser.error(str(len(rfiles)) + " restart files given, but only one "
                     "restart file can be processed at a time")

    elif len(rfiles) and len(rfiles) != len(args):
        # choose to run a single restart file or input files, but don't mix
        parser.error("Cannot process both restart and input files at same time")

    elif len(rfiles):
        # check to see if the input file exists and get it info
        rfile = rfiles[0]
        if not os.path.isfile(rfile):
            parser.error("Restart file {0} not found".format(rfile))
            pass
        restart = True
        with open(rfile,"rb") as f: the_model = pickle.load(f)
        user_input_dict = {"restart":the_model}

    else:
        # get a list of all input files, order of where to look for file f:
        # 1: f
        # 2: realpath(f)
        # 3: join(Aux/Inputs,f)
        # 4: splitext(f)[0] + .inp
        # 5: join(Aux/Inputs,splitext(f)[0] + .inp)
        foundf, badf = [], []
        for iarg,arg in enumerate(args):
            f = None
            fbase,fext = os.path.splitext(arg)
            if not arg: continue
            if fext == ".prf":
                # one last check for restart files
                parser.error("Cannot process both restart and input "
                             "files at same time")
            elif os.path.isfile(arg):
                f = arg
            elif os.path.isfile(os.path.realpath(arg)):
                f = os.path.realpath(arg)
            elif os.path.isfile(os.path.join(Payette_Inputs,arg)):
                f = os.path.join(Payette_Inputs,arg)
                writeMessage(__file__,"Using " + f + " as input")
            elif not fext or fext == ".":
                # add .inp extension to arg
                arginp = fbase + ".inp"
                if os.path.isfile(arginp):
                    f = arginp
                    writeMessage(__file__,"Using " + f + " as input")
                elif os.path.isfile(os.path.join(Payette_Inputs,arginp)):
                    f = os.path.join(Payette_Inputs,arginp)
                    writeMessage(__file__,"Using " + f + " as input")
                else: pass
                pass

            if not f:
                writeWarning(__file__,"{0} not found in {1}, {2}, or {3}"
                             .format(arg,os.path.dirname(os.path.realpath(arg)),
                                     os.getcwd(),Payette_Inputs))
                badf.append(arg)
                continue

            if f in foundf:
                parser.error("{0} given multiple times".format(arg))
                pass

            foundf.append(f)
            continue

        if badf:
            writeWarning(__file__,"The following files were not found: {0}"
                         .format(", ".join(badf)))
            pass

        if not foundf and not input_lines:
            parser.print_help()
            parser.error("No input files found")
            pass

        # we now have a list of input files, put there contents in to input lines
        for f in foundf:
            input_lines.extend(open(f,"r").readlines())
            continue

        # read the user input
        user_input_dict = readUserInput(input_lines,opts.cchar)
        if not user_input_dict:
            sys.exit("ERROR: user input not found in {0:s}".format(infile))
            pass
        pass
    # ------------------------------------------------------- end: get user input

    # number of processors
    nproc = min(min(mp.cpu_count(),opts.nproc),len(user_input_dict))
    opts.verbosity = int(opts.verbosity) if nproc == 1 else 0

    if nproc > 1:
        writeWarning(__file__,
                     "Running with multiple processors.  Logging to the console\n"
                     "         has been turned off.  If a job hangs, [ctrl-c] at the\n"
                     "         console will not shut down Payette.  Instead, put the job\n"
                     "         in the background with [ctrl-z] and then kill it")

    # loop through simulations and run them
    if opts.timing: t0 = time.time()
    if nproc > 1 and len(user_input_dict.keys()) > 1:
        p = mp.Pool(processes=nproc)
        p.map(runJob,user_input_dict.keys())
        p.close()
        p.join()
    else:
        for key in user_input_dict:
            runJob(key)
            continue
        pass
    if opts.timing: printFinalTimingInfo(t0)

    return 0

def runJob(key):
    # instantiate Payette object
    if opts.timing: t0 = time.time()

    if restart:
        the_model = user_input_dict[key]
        the_model.setupRestart()
    else: the_model = pcntnr.Payette(key,user_input_dict[key],opts)

    # run the problem
    if opts.timing: t1 = time.time()
    solve = pdrvr.runProblem(the_model,restart)
    if opts.timing: t2 = time.time()
    if solve == 0:
        reportMessage(__file__,"%s Payette simulation ran to completion"
                      %the_model.name)
    else:
        reportMessage(__file__,"%s Payette simulation failed\n\n"
                      %the_model.name)
        return 1

    # finish up
    the_model.finish()
    del the_model

    # print timing info
    if opts.timing: printTimingInfo(t0,t1,t2,the_model.name)
    return

def printTimingInfo(t0,t1,t2,name=None):
    ttot = time.time() - t0
    texe = t2 - t1
    print("\n-------------- %s timing info --------------"%name)
    print("total problem execution time:\t%f"%texe)
    print("total simulation time:\t\t%f\n"%ttot)
    return None

def printFinalTimingInfo(t0):
    ttot = time.time() - t0
    print("\n-------------- simulation timing info --------------")
    print("total simulation time:\t\t%f"%ttot)
    return None

def testPayette(argc,argv):
    """
    NAME
       testPayette

    PURPOSE
       walk through and run the Payette test simulations, compare results
       against the accepted results

    AUTHORS
       Tim Fuller, Sandia National Laboratories, tjfulle@sandia.gov
       M. Scot Swan, Sandia National Laboratories, mswan@sandia.gov
    """
    import platform
    import datetime # For the date of when the tests were run
    import getpass  # For finding the username of the person running this
    import Payette_testing_tools as ptt
    import Payette_notify

    global testresdir,rantests,topts

    # *************************************************************************
    # -- command line option parsing
    usage = "usage: testPayette [options]"
    parser = optparse.OptionParser(usage = usage, version = "%prog 1.0")
    parser.add_option("-k",
                      dest = "KEYWORDS",
                      action = "append",
                      default = [],
                      help = "keywords: [%default]")
    parser.add_option("-K",
                      dest = "NOKEYWORDS",
                      action = "append",
                      default = [],
                      help = "keyword negation: [%default]")
    parser.add_option("-t",
                      dest = "SPECTESTS",
                      action = "append",
                      default = [],
                      help = ("specific tests to run, more than 1 collected: "
                              "[%default]"))
    parser.add_option("-d","--dir",
                      dest="TESTDIR",
                      action="store",
                      default=Payette_Tests,
                      help="Directory to scan for benchmarks [default: %default].")
    parser.add_option("-i","--index",
                      dest="INDEX",
                      action="store_true",
                      default=False,
                      help="Print benchmarks index [default: %default].")
    parser.add_option("-r","--run",
                      dest="RUN",
                      action="store_true",
                      default=False,
                      help="Run benchmarks. [default: %default].")
    parser.add_option("-F",
                      dest="FORCERERUN",
                      action="store_true",
                      default=False,
                      help=("Force benchmarks to be run again if already ran. "
                            "[default: %default]."))
    parser.add_option("-j","--nproc",
                      dest = "nproc",
                      type = int,
                      default = 1,
                      action = "store")
    parser.add_option("-b","--buildpayette",
                      dest="buildpayette",
                      action="store_true",
                      default=False,
                      help=("build payette [default: %default]."))
    parser.add_option("-p","--postprocess",
                      dest = "POSTPROCESS",
                      action = "store_true",
                      default=False,
                      help=("Generate all plots for all tests to be viewed in browser"))
    parser.add_option("--notify",
                      dest = "NOTIFY",
                      action = "store_true",
                      default=False,
                      help=("Sends an email with the test results to the mailing list."))

    (topts,args) = parser.parse_args(argv)

    # number of processors
    nproc = min(mp.cpu_count(),topts.nproc)

    # assume the user wants to run the tests
    if not topts.RUN and not topts.INDEX: topts.RUN = True
#        sys.exit("Please specify either run the tests (-r) "
#                 "or print index of tests (-i)")
    # get list of tests to run
    conforming,nonconforming = [],[]
    for (dirname,dirs,names) in os.walk(topts.TESTDIR):
        found_tests = ptt.findTests(dirname,names,topts.KEYWORDS,
                                    topts.NOKEYWORDS,topts.SPECTESTS)
        conforming += found_tests[0]
        nonconforming += found_tests[1]

        continue

    # find mathematica notebooks
    mathnbs = []
    for (dirname,dirs,names) in os.walk(topts.TESTDIR):
        root, base = os.path.split(dirname)
        if base == "nb":
            # a notebook directory has been found, see if there are any
            # conforming tests that use it
            if [x for x in conforming if root in x]:
                tmp = [root.split(topts.TESTDIR+os.sep)[1]]
                tmp.extend([ os.path.join(dirname,x) for x in names
                             if x.endswith(".nb") or x.endswith(".m") ])
                mathnbs.append(tmp)
                pass
            pass
        continue

    if len(nonconforming):
        print("The following benchmarks do not conform:")
        for test in nonconforming:
            msg = ("%s is missing the following attributes: %s"%(test[0],test[1]))
            print(msg)
            continue
        sys.exit("Fix nonconforming benchmarks before continuing")
        pass

    if topts.INDEX:
        out = sys.stderr
        out.write("\n\nBENCHMARK INDEX\n\n")
        for pyfile in conforming:
            fbase,fext = os.path.splitext(pyfile)
            with open(pyfile) as f:
                fmod = imp.load_module(fbase,f,pyfile,("py","U",imp.PY_SOURCE))
                pass
            out.write(72*"="+"\n")
            out.write("Name:  {0}\n".format(fmod.name))
            out.write("Owner: {0}\n\n".format(fmod.owner))
            out.write("Description:\n{0}".format(fmod.description))

            out.write("\nKeywords:\n")
            for tok in fmod.keywords: out.write("    {0}\n".format(tok))
        pass

    # sort conforming tests from long to fast
    fst,mdm,lng = [],[],[]
    for pyfile in conforming:
        fbase,fext = os.path.splitext(pyfile)
        with open(pyfile) as f:
            fmod = imp.load_module(fbase,f,pyfile,("py","U",imp.PY_SOURCE))
            pass
        if "fast" in fmod.keywords: fst.append(pyfile)
        elif "medium" in fmod.keywords: mdm.append(pyfile)
        elif "long" in fmod.keywords: lng.append(pyfile)
        else: pass
        continue
    conforming = lng + mdm + fst

    if topts.RUN:
        # start the timer
        runtimer = time.time()

        # Make a TestResults directory named "TestResults.{platform}"
        testresdir = os.path.join(os.getcwd(),"TestResults.%s"%platform.system())
        if topts.buildpayette:
            if os.path.isdir(testresdir):
                testresdir0 = "%s_0"%testresdir
                shutil.move(testresdir,testresdir0)
            else: testresdir0 = None
            pass

        if not os.path.isdir(testresdir): os.mkdir(testresdir)

        summpy,tres = os.path.join(testresdir,"summary.py"), None
        summhtml = os.path.splitext(summpy)[0] + ".html"
        if not os.path.isfile(summpy): pass
        else:
            try:
                # summary file exists, load it and get test results
                fbase,fext = os.path.splitext(os.path.basename(summpy))
                with open(summpy) as f:
                    fmod = imp.load_module(fbase,f,summpy,("py","U",imp.PY_SOURCE))
                    pass
                try: tres = fmod.payette_test_results
                except: copyfile(summpy,os.path.join(testresdir,"summary_orig.py"))
                try: os.remove("%sc"%summpy)
                except: pass
                pass
            except: pass

        # check type of tres, if not dict start over with empty dict
        if not isinstance(tres,dict): tres = {}

        # Put all run tests in a flattened list for checking if test has been run
        if tres: rantests = [x for y in tres.values() for x in y]
        else: rantests = []

        # reset tres
        test_res = {}
        for i in ["pass","diff","fail","notrun"]: test_res[i] = {}

        print("="*72)
        print("Running {0} benchmarks:".format(len(conforming)))
        print("="*72)

        # run the tests on multiple processors using the multiprocessor map
        # ONLY if nprocs > 1. For debug purposes, when nprocs=1, run without
        # using the multiprocessor map because it makes debugging worse than
        # it should be.
        if nproc == 1:
            l = [runPayetteTest(tmpvar) for tmpvar in conforming]
        else:
            p = mp.Pool(processes=nproc)
            l = p.map(runPayetteTest,conforming)
            p.close()
            p.join()
        ttot = time.time()-runtimer
        print("="*72)

        # copy the mathematica notebooks to the output directory
        if mathnbs:
            for mathnb in mathnbs:
                stub = mathnb[0]
                for item in mathnb[1:]:
                    fbase = os.path.basename(item)
                    fold = os.path.join(testresdir,stub,fbase)

                    if os.path.isfile(fold):
                        continue

                    if item.endswith(".m"):
                        # don't copy the .m file, but write it, replacing rundir
                        # and demodir with testresdir
                        with open(fold,"w") as f:
                            for line in open(item,"r").readlines():
                                demodir = os.path.join(testresdir,stub) + os.sep
                                rundir = os.path.join(testresdir,stub) + os.sep
                                if r"$DEMODIR" in line:
                                    line = 'demodir="{0:s}"\n'.format(demodir)
                                elif r"$RUNDIR" in line:
                                    line = 'rundir="{0:s}"\n'.format(rundir)
                                else:
                                    pass
                                f.write(line)
                                continue
                            pass

                    else:
                        # copy the notebook files
                        shutil.copyfile(item,fold)
                        pass

                    continue

                continue

            pass


        # reconstruct test_res from l
        for d in l:
            name = d.keys()[0]
            retcode = d[name][0]
            test_res[retcode][name] = d[name][1:]

        txtsummary = ( "SUMMARY\n" +
                      "{0} benchmarks took {1:.2f}s.\n".format(len(conforming),ttot) +
                      "{0} benchmarks passed\n".format(len(test_res["pass"])) +
                      "{0} benchmarks diffed\n".format(len(test_res["diff"])) +
                      "{0} benchmarks failed\n".format(len(test_res["fail"])) +
                      "{0} benchmarks not run\n".format(len(test_res["notrun"])) +
                      "For a summary of which benchmarks passed, diffed, failed, " +
                      "or not run, see\n{0}".format(summhtml))

        ######################################################################
        # Make a long summary including the names of what passed and what didn't
        # as well as system information.
        str_date = datetime.datetime.today().strftime("%A, %d. %B %Y %I:%M%p")
        try:
            py_version = "{0}.{1}.{2}".format(sys.version_info.major,
                                              sys.version_info.minor,
                                              sys.version_info.micro)
        except:
            py_version = str(sys.version_info)

        longtxtsummary = (
             "="*72+"\nLONG SUMMARY\n"+
             "{0} benchmarks took {1:.2f}s.\n".format(len(conforming),ttot) +
             "{0:^72}\n".format("{0:-^30}".format(" system information "))+
             "   Date complete:    {0:<}\n".format(str_date)+
             "   Username:         {0:<}\n".format(getpass.getuser())+
             "   Hostname:         {0:<}\n".format(os.uname()[1])+
             "   Platform:         {0:<}\n".format(sys.platform)+
             "   Python Version:   {0:<}\n".format(py_version))

        # List each category (diff, fail, notrun, and pass) and the tests
        test_res_keys = test_res.keys()
        test_res_keys.sort()
        for key in test_res_keys:
            test_names = test_res[key].keys()
            header = "{0:-^30}".format(" "+key+" ({0}) ".format(len(test_names)))
            longtxtsummary += "{0:^72}\n".format(header)
            if len(test_names) == 0:
#                longtxtsummary += "None\n"
                continue
            elif key == "notrun":
#                longtxtsummary += "None\n"
                continue
            for test_name in test_names:
                test_t = test_res[key][test_name][1][1]
                longtxtsummary += "  {0:>8}   {1}\n".format(test_t,test_name)
        longtxtsummary += "="*72 + "\n"
        # longtxtsummary is finished at this point
        ######################################################################

        # This sends an email to everyone on the mailing list.
        if topts.NOTIFY:
            print("Sending results to mailing list.")
            Payette_notify.notify("Payette Benchmarks",longtxtsummary)

        print(longtxtsummary)
        print("="*72)
        print(txtsummary)
        print("="*72)

        # write out the results to the summary file
        writePyTestSummary(summpy,test_res)
        writeHTMLTestSummary(summhtml,test_res)

        # cleanup our tracks
        for (dirname,dirs,names) in os.walk(topts.TESTDIR):
            for name in names:
                fbase,fext = os.path.splitext(name)
                delext = [".so",".pyo",".pyc",".log",".out",".prf"]
                if fext in delext: os.remove(os.path.join(dirname,name))
                continue
            continue

        if topts.buildpayette:
            shutil.rmtree(testresdir)
            if testresdir0: shutil.move(testresdir0,testresdir)
            pass
        pass

    return 0

def runPayetteTest(pyfile):
    cwd = os.getcwd()
    fbase,fext = os.path.splitext(pyfile)

    # open module
    with open(pyfile) as f:
        fmod = imp.load_module(fbase,f,pyfile,("py","U",imp.PY_SOURCE))
        pass

    # directory where test will be run
    testbase = os.path.dirname(pyfile).split(Payette_Tests + os.sep)[1]
    benchdir = os.path.join(testresdir,testbase,fmod.name)

    # check if benchmark has been run
    ran = [x for x in rantests if x == fmod.name]
    if not topts.FORCERERUN and ran and os.path.isdir(benchdir):
        print(  "%s"%(fmod.name)
                + " "*(50-len(fmod.name))
                + "{0:>10s}".format("notrun\n")
                + "Test already ran. "
                + "Use -F option to force a rerun")
        #test_res["notrun"][fmod.name] = [fmod.keywords,[]]
        return {fmod.name:["notrun",fmod.keywords,["Exit notrun","NA"],benchdir]}

    # Let the user know which test is running
    print(  "%s"%(fmod.name)
            + " "*(50-len(fmod.name))
            + "{0:>10s}".format("RUNNING"))

    # Create benchdir and copy the input and baseline files into the new
    # directory
    if os.path.isdir(benchdir): rmtree(benchdir)
    os.makedirs(benchdir)
    if fmod.infile:
        copyfile(fmod.infile,os.path.join(benchdir,os.path.basename(fmod.infile)))
    copyfile(pyfile,
             os.path.join(benchdir,os.path.basename(pyfile)))
    os.chmod(os.path.join(benchdir,os.path.basename(pyfile)),0o750)
    with open(os.path.join(benchdir,"tests_common.py"),"w") as tcpy:
        tcpy.write("import os,sys\n")
        tcpy.write("tests_d = '%s'\n"%topts.TESTDIR)
        trunkd = os.path.dirname(topts.TESTDIR)
        tcpy.write("trunk_d = '%s'\n"%trunkd)
        tcpy.write("source_d = '%s'\n"%os.path.join(trunkd,'Source'))
        tcpy.write("tools_d = '%s'\n"%os.path.join(trunkd,'Toolset'))
        tcpy.write("sys.path.append(tools_d)\n")
        tcpy.write("sys.path.append(source_d)\n")
        tcpy.write("sys.path.append(trunk_d)\n")
        tcpy.write("sys.path.append(tests_d)\n")
        pass
    if hasattr(fmod,'baseline') and fmod.baseline:
        if isinstance(fmod.baseline,list):
            for base_f in fmod.baseline:
                os.symlink(base_f,
                           os.path.join(benchdir,os.path.basename(base_f)))
                continue
        else:
            os.symlink(fmod.baseline,
                       os.path.join(benchdir,os.path.basename(fmod.baseline)))


    # move to the new directory and run the test
    os.chdir(benchdir)
    starttime = time.time()

    retcode = fmod.runTest()
    if topts.POSTPROCESS and os.path.isfile(os.path.join(fmod.outfile)):
        import postprocess as PP
        PP.postprocess(os.path.join(fmod.outfile),verbosity=0)


    retcode = ("pass" if retcode== 0 else
               "diff" if retcode== 1 else "fail")

    # Print output at completion
    tcompletion = time.time()-starttime
    print(  "%s"%(fmod.name)
            + " "*(50-len(fmod.name))
            + "{0:>10s}".format(retcode)
            + "({0:6.02f}s)".format(tcompletion))

    # update the test results dictionary
    #test_res[retcode][fmod.name] = [fmod.keywords,["Exit %s"%retcode,
    #                                           "%ss"%str(round(tcompletion,2))]]
    os.chdir(cwd)
    return {fmod.name:[retcode,fmod.keywords,["Exit %s"%retcode,"%ss"%str(round(tcompletion,2))],benchdir]}

def writePyTestSummary(fname,results):
    with open(fname,"w") as f:
        f.write("payette_test_results = {}\n")
        for k in results:
            f.write("payette_test_results['%s']=["%k)
            f.write(",".join(["'%s'"%x for x in results[k].keys()]))
            f.write("]\n")
            continue
        pass
    return

def writeHTMLTestSummary(fname,results):
    resd = os.path.dirname(fname)
    resdb = os.path.basename(resd)
    npass,nfail,ndiff,nskip = [len(results[x]) for x in
                               ["pass","fail","diff","notrun"]]
    with open(fname,"w") as f:
        # write header
        f.write("<html>\n<head>\n<title>Test Results</title>\n</head>\n")
        f.write("<body>\n<h1>Summary</h1>\n")
        f.write("<ul>\n")
        f.write("<li> Directory: %s </li>\n"%resd)
        f.write("<li> Options: %s </li>\n"%(" ".join(sys.argv[1:])))
        f.write("<li> %i pass, %i diff, %i fail, %i notrun </li>\n"
                %(npass,ndiff,nfail,nskip))
        f.write("</ul>\n")

        # write out details test that fail, diff, pass, notrun
        for stat in results.keys():
            f.write("<h1>Tests that showed '%s'</h1>\n<ul>\n"%stat)
            for test in results[stat]:
                tresd = results[stat][test][-1]
                tresdb = results[stat][test][-1]
                f.write("<li>%s  %s</li>\n"%(test,tresdb))
                f.write("<ul>\n")
                f.write("<li>Files: \n")
                files = os.listdir(tresd)
                for ff in files:
                    fpath = os.path.join(tresd,ff)
                    f.write("<a href='%s' type='text/plain'>%s</a> \n"%(fpath,ff))
                    continue
                keywords = "  ".join(results[stat][test][0])
                status = "  ".join(results[stat][test][1])
                for myfile in files:
                    if myfile.endswith(".out.html") and topts.POSTPROCESS:
                        tf = os.path.join(tresd,myfile)
                        f.write("<li><a href='{0}'>PostProcessing</a>\n".format(tf))
                f.write("<li>Keywords: %s\n"%(keywords))
                f.write("<li>Status: %s\n"%(status))
                f.write("</ul>\n")
                continue
            f.write("</ul>\n")
            continue
        pass
    return

def Payette(args):
    """
    NAME
       Payette

    PURPOSE
       Main function that calls either runPayette or testPayette

    AUTHORS
       Tim Fuller, Sandia National Laboratories, tjfulle@sandia.gov
    """
    if "--profile" in args:
        profile = True
        args.remove("--profile")
        import cProfile
    else: profile = False

    if args and args[1] == "test":
        args.remove("test")
        if profile:
            cmd = "testPayette(len(args[1:]),args[1:])"
            f = "payette.prof"
            cProfile.runctx(cmd,globals(),locals(),f)
            payette = 0
        else: payette = testPayette(len(args[1:]),args[1:])

    elif args and args[1] == "run":
        args.remove("run")
        if profile:
            cmd = "runPayette(len(args[1:]),args[1:])"
            f = "payette.prof"
            cProfile.runctx(cmd,globals(),locals(),f)
            payette = 0
        else: payette = runPayette(len(args[1:]),args[1:])

    else:
        print("ERROR: first argument to Payette must be either run or test")
        print_help()
        return 1
        pass

    return payette

def print_help():
    print("""
NAME
   Payette

PURPOSE
   Payette is a object oriented single element material model driver written in
   python.

USAGE
   Payette <test,run> [options] <filename>
""")
    return

if __name__ == "__main__":

    # Make sure we run this script under python 2.6
    checkPythonVersion()
    payette = Payette(sys.argv)
    sys.exit(payette)


